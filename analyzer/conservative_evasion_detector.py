"""
Conservative Evasion-Resistant AI Detection Engine
Calibrated for realistic 10-15% detection rates while maintaining evasion resistance
"""

import re
import ast
import json
from typing import Dict, List, Any, Set, Tuple
from collections import Counter, defaultdict
import statistics

class ConservativeEvasionDetector:
    def __init__(self, indicators_config: Dict[str, Any]):
        self.config = indicators_config
        self._initialize_conservative_patterns()
        self._initialize_conservative_weights()
        self._initialize_thresholds()
    
    def _initialize_conservative_patterns(self):
        """Initialize conservative patterns with higher confidence requirements"""
        
        # Only the strongest AI indicators
        self.strong_ai_patterns = {
            'explicit_ai_markers': [
                r'#\s*(?:Generated by|Created by|Code by)\s*(?:Copilot|AI|GPT|Claude)',
                r'//\s*(?:Generated by|Created by|Code by)\s*(?:Copilot|AI|GPT|Claude)',
                r'/\*\s*(?:Generated by|Created by|Code by)\s*(?:Copilot|AI|GPT|Claude)',
                r'#\s*AI-generated',
                r'//\s*AI-generated',
            ],
            
            'very_strong_semantic_patterns': [
                r'def\s+\w+\([^)]*\)\s*->\s*(?:Optional\[.*\]|Union\[.*\]|Dict\[.*\]):\s*\n\s*"""[\s\S]*?Args:[\s\S]*?Returns:[\s\S]*?"""',
                r'try:\s*\n[^}]*except\s+Exception\s+as\s+e:\s*\n\s*(?:print\(|logger\.|pass\s*$)',
                r'if\s+\w+\s+is\s+not\s+None\s+and\s+len\(\w+\)\s*>\s*0\s+and\s+isinstance\(\w+,',
                r'for\s+\w+\s+in\s+range\(len\(\w+\)\):\s*\n\s*if\s+\w+\[.*\]\s+is\s+not\s+None:',
            ],
            
            'multiple_pattern_clusters': [
                # Require multiple patterns in close proximity
                r'(?:def|class)\s+\w+.*?(?:Args:|Returns:|Raises:).*?(?:Exception|ValueError|TypeError)',
                r'(?:validate|check|verify)\w*.*?(?:if.*is.*None|isinstance|hasattr).*?(?:raise|return)',
                r'(?:List|Dict|Optional)\[.*?\].*?(?:= None|= \[\]|= {}).*?(?:if.*is.*None|len\(.*\) > 0)',
            ],
            
            'java_strong_patterns': [
                # Java-specific strong AI patterns
                r'public\s+(?:static\s+)?(?:void|\w+)\s+\w+\([^)]*\)\s+throws\s+Exception\s*\{[\s\S]*?catch\s*\(\s*Exception\s+e\s*\)\s*\{[\s\S]*?e\.printStackTrace\(\)',
                r'@Override\s*\n\s*public\s+(?:boolean\s+equals|int\s+hashCode|String\s+toString)\([^)]*\)\s*\{[\s\S]*?Objects\.(?:equals|hash)',
                r'public\s+class\s+\w+\s*\{[\s\S]*?private\s+static\s+final\s+Logger\s+logger\s*=\s*LoggerFactory\.getLogger',
                r'@Autowired\s*\n\s*private\s+\w+\s+\w+Service;\s*\n[\s\S]*?@RequestMapping',
            ]
        }
        
        # AI naming that's very distinctive
        self.distinctive_ai_naming = [
            r'\b(?:data|result|response|output|input)_\d+\b',  # Numbered generic variables
            r'\b(?:temp|tmp)_(?:data|result|value|obj)\b',     # AI temporary naming
            r'\b(?:process|handle|execute)_(?:data|input|request)_\w+\b',  # AI method naming
            r'\b(?:validate|check|verify)_(?:input|data|params)_\w+\b',    # AI validation naming
        ]
        
        # Java-specific AI naming patterns
        self.java_distinctive_naming = [
            r'\b(?:userData|responseData|requestData|inputData)\d*\b',  # Java camelCase AI naming
            r'\b(?:tempObject|tempValue|tempResult)\d*\b',             # Java temporary naming
            r'\b(?:processUserData|handleUserRequest|executeUserAction)\b',  # Java method naming
            r'\b(?:validateUserInput|checkUserData|verifyUserParams)\b',     # Java validation naming
            r'\b(?:userDataProcessor|requestDataHandler|responseDataBuilder)\b',  # Java class naming
        ]
        
        # Complex AI structures that are hard to fake
        self.complex_ai_structures = [
            r'class\s+\w+:\s*\n(?:\s*"""[\s\S]*?"""\s*\n)?\s*def\s+__init__\(self[^)]*\):\s*\n[\s\S]*?if.*is.*None.*raise.*Exception',
            r'@(?:staticmethod|classmethod)\s*\n\s*def\s+\w+\([^)]*\)\s*->\s*(?:Optional|Union|Dict).*?:\s*\n\s*"""[\s\S]*?Args:',
            r'def\s+\w+\([^)]*\)\s*->\s*(?:Generator|Iterator|Callable).*?:\s*\n\s*"""[\s\S]*?Yields:[\s\S]*?"""',
        ]
    
    def _initialize_conservative_weights(self):
        """Initialize conservative weights favoring high-confidence indicators"""
        self.weights = {
            'explicit_markers': 0.40,     # Very high weight for explicit markers
            'strong_semantics': 0.25,     # Strong semantic patterns
            'distinctive_naming': 0.15,   # Distinctive AI naming
            'complex_structures': 0.10,   # Complex AI structures
            'evasion_resistance': 0.10,   # Evasion detection
        }
    
    def _initialize_thresholds(self):
        """Initialize conservative thresholds"""
        self.thresholds = {
            'high_confidence': 0.85,      # Very high threshold for HIGH risk
            'medium_confidence': 0.55,    # Moderate threshold for MEDIUM risk  
            'low_confidence': 0.30,       # Conservative threshold for LOW risk
            'minimal_threshold': 0.15,    # Below this is MINIMAL
        }
        
        # Calibration multipliers to achieve 10-15% realistic detection
        self.calibration = {
            'base_reduction': 0.60,       # Reduce base confidence by 40%
            'file_size_factor': 0.85,     # Larger files get slight reduction
            'language_factors': {
                'python': 1.0,            # Python baseline
                'javascript': 0.8,        # JS slightly lower
                'java': 0.9,              # Java moderate
                'typescript': 0.85,       # TS moderate
            }
        }
    
    def analyze_content(self, content: str, file_extension: str) -> Dict[str, Any]:
        """Conservative analysis with realistic detection rates"""
        
        if not content.strip():
            return self._create_empty_analysis()
        
        # Get raw confidence scores
        explicit_score = self._detect_explicit_markers(content)
        semantic_score = self._detect_strong_semantics(content)
        naming_score = self._detect_distinctive_naming(content)
        structure_score = self._detect_complex_structures(content)
        evasion_score = self._detect_evasion_resistance(content)
        
        # Calculate weighted confidence
        raw_confidence = (
            explicit_score * self.weights['explicit_markers'] +
            semantic_score * self.weights['strong_semantics'] +
            naming_score * self.weights['distinctive_naming'] +
            structure_score * self.weights['complex_structures'] +
            evasion_score * self.weights['evasion_resistance']
        )
        
        # Apply conservative calibration
        calibrated_confidence = self._apply_conservative_calibration(
            raw_confidence, content, file_extension
        )
        
        # Determine risk level and estimated lines
        risk_level = self._calculate_conservative_risk(calibrated_confidence)
        estimated_lines = self._calculate_estimated_lines(calibrated_confidence, content)
        
        # Detect evasion attempts
        evasion_indicators = self._detect_evasion_attempts(content)
        
        return {
            'copilot_confidence': calibrated_confidence,
            'confidence_score': calibrated_confidence,  # Backward compatibility
            'estimated_lines': estimated_lines,
            'risk_level': risk_level,
            'language': self._detect_language(file_extension),
            'conservative_analysis': {
                'explicit_score': explicit_score,
                'semantic_score': semantic_score,
                'naming_score': naming_score,
                'structure_score': structure_score,
                'evasion_score': evasion_score,
                'raw_confidence': raw_confidence,
                'calibration_applied': raw_confidence - calibrated_confidence
            },
            'evasion_resistance': {
                'evasion_detected': len(evasion_indicators) > 0,
                'evasion_indicators': evasion_indicators,
                'maintains_detection': calibrated_confidence > 0.15  # Still detected despite evasion
            },
            'explanation': self._generate_conservative_explanation(
                calibrated_confidence, explicit_score, semantic_score, evasion_indicators
            )
        }
    
    def _detect_explicit_markers(self, content: str) -> float:
        """Detect explicit AI markers - highest confidence"""
        score = 0.0
        
        for pattern in self.strong_ai_patterns['explicit_ai_markers']:
            matches = re.findall(pattern, content, re.IGNORECASE | re.MULTILINE)
            if matches:
                score = 1.0  # Any explicit marker = maximum confidence
                break
        
        return score
    
    def _detect_strong_semantics(self, content: str) -> float:
        """Detect very strong semantic AI patterns"""
        total_score = 0.0
        pattern_count = 0
        
        # Strong semantic patterns
        for pattern in self.strong_ai_patterns['very_strong_semantic_patterns']:
            matches = re.findall(pattern, content, re.MULTILINE | re.DOTALL)
            if matches:
                total_score += min(len(matches) * 0.3, 0.8)
            pattern_count += 1
        
        # Java-specific strong patterns
        for pattern in self.strong_ai_patterns['java_strong_patterns']:
            matches = re.findall(pattern, content, re.MULTILINE | re.DOTALL)
            if matches:
                total_score += min(len(matches) * 0.4, 0.9)  # Higher weight for Java patterns
            pattern_count += 1
        
        # Multi-pattern clusters (require multiple indicators)
        cluster_score = 0.0
        for pattern in self.strong_ai_patterns['multiple_pattern_clusters']:
            if re.search(pattern, content, re.MULTILINE | re.DOTALL):
                cluster_score += 0.4
        
        combined_score = (total_score / max(pattern_count, 1)) + min(cluster_score, 0.6)
        return min(combined_score, 1.0)
    
    def _detect_distinctive_naming(self, content: str) -> float:
        """Detect distinctive AI naming patterns"""
        total_names = len(re.findall(r'\b[a-zA-Z_][a-zA-Z0-9_]*\b', content))
        if total_names == 0:
            return 0.0
        
        ai_name_count = 0
        
        # Check Python-style naming
        for pattern in self.distinctive_ai_naming:
            matches = re.findall(pattern, content)
            ai_name_count += len(matches)
        
        # Check Java-style naming
        for pattern in self.java_distinctive_naming:
            matches = re.findall(pattern, content)
            ai_name_count += len(matches)
        
        # Require significant proportion of AI naming
        naming_ratio = ai_name_count / total_names
        if naming_ratio > 0.15:  # More than 15% AI-style names
            return min(naming_ratio * 2, 1.0)
        else:
            return 0.0
    
    def _detect_complex_structures(self, content: str) -> float:
        """Detect complex AI code structures"""
        structure_score = 0.0
        
        for pattern in self.complex_ai_structures:
            if re.search(pattern, content, re.MULTILINE | re.DOTALL):
                structure_score += 0.4
        
        return min(structure_score, 1.0)
    
    def _detect_evasion_resistance(self, content: str) -> float:
        """Detect evasion attempts but with conservative scoring"""
        evasion_indicators = self._detect_evasion_attempts(content)
        
        # Only score if multiple evasion indicators present
        if len(evasion_indicators) >= 2:
            return 0.3
        elif len(evasion_indicators) == 1:
            return 0.1
        else:
            return 0.0
    
    def _apply_conservative_calibration(self, raw_confidence: float, content: str, file_extension: str) -> float:
        """Apply conservative calibration to achieve 10-15% detection rates"""
        
        # Apply base reduction
        calibrated = raw_confidence * self.calibration['base_reduction']
        
        # Apply file size factor (larger files get slight penalty)
        line_count = len(content.split('\n'))
        if line_count > 200:
            calibrated *= self.calibration['file_size_factor']
        
        # Apply language factor
        language = self._detect_language(file_extension)
        lang_factor = self.calibration['language_factors'].get(language, 0.8)
        calibrated *= lang_factor
        
        # Additional conservative adjustment for realistic rates
        if calibrated > 0.3:
            calibrated = 0.3 + (calibrated - 0.3) * 0.5  # Compress high values
        
        return min(calibrated, 1.0)
    
    def _calculate_conservative_risk(self, confidence: float) -> str:
        """Calculate risk level with conservative thresholds"""
        if confidence >= self.thresholds['high_confidence']:
            return "HIGH"
        elif confidence >= self.thresholds['medium_confidence']:
            return "MEDIUM"
        elif confidence >= self.thresholds['low_confidence']:
            return "LOW"
        else:
            return "MINIMAL"
    
    def _calculate_estimated_lines(self, confidence: float, content: str) -> int:
        """Calculate estimated AI lines conservatively"""
        code_lines = len([line for line in content.split('\n') if line.strip() and not line.strip().startswith('#')])
        
        # Conservative line estimation
        if confidence >= 0.7:
            return int(code_lines * confidence * 0.8)  # High confidence but conservative
        elif confidence >= 0.4:
            return int(code_lines * confidence * 0.6)  # Medium confidence, more conservative
        else:
            return int(code_lines * confidence * 0.4)  # Low confidence, very conservative
    
    def _detect_evasion_attempts(self, content: str) -> List[str]:
        """Detect evasion attempts with higher threshold"""
        evasion_indicators = []
        
        # Only flag clear evasion attempts
        lines = content.split('\n')
        
        # Systematic variable renaming (higher threshold)
        var_names = re.findall(r'\b[a-z][a-zA-Z0-9_]*\b', content)
        single_letter_vars = len([name for name in var_names if len(name) == 1])
        if len(var_names) > 20 and single_letter_vars / len(var_names) > 0.4:
            evasion_indicators.append('systematic_variable_renaming')
        
        # Excessive formatting (higher threshold)
        if len(lines) > 50:
            empty_lines = len([line for line in lines if not line.strip()])
            if empty_lines / len(lines) > 0.4:
                evasion_indicators.append('excessive_formatting_changes')
        
        # Comment insertion to break patterns (higher threshold)
        comment_lines = len([line for line in lines if line.strip().startswith('#')])
        code_lines = len([line for line in lines if line.strip() and not line.strip().startswith('#')])
        
        if code_lines > 0 and comment_lines / code_lines > 0.6:
            evasion_indicators.append('excessive_comment_insertion')
        
        return evasion_indicators
    
    def _generate_conservative_explanation(self, confidence: float, explicit_score: float, 
                                         semantic_score: float, evasion_indicators: List[str]) -> List[str]:
        """Generate conservative explanation"""
        explanation = []
        
        if explicit_score > 0:
            explanation.append("Explicit AI markers detected in code")
        
        if confidence >= 0.5:
            explanation.append("Strong AI-generated code patterns detected")
        elif confidence >= 0.25:
            explanation.append("Moderate AI-generated code patterns detected")
        elif confidence >= 0.15:
            explanation.append("Minimal AI-generated code patterns detected")
        else:
            explanation.append("No significant AI patterns detected")
        
        if semantic_score > 0.4:
            explanation.append("Strong semantic patterns typical of AI generation")
        
        if evasion_indicators:
            explanation.append(f"Potential evasion attempts: {', '.join(evasion_indicators)}")
        
        if confidence < 0.15:
            explanation.append("Code appears to be primarily human-written")
        
        return explanation
    
    def _detect_language(self, file_extension: str) -> str:
        """Detect programming language from file extension"""
        language_map = {
            '.py': 'python',
            '.js': 'javascript',
            '.ts': 'typescript',
            '.java': 'java',
            '.cpp': 'cpp',
            '.c': 'c',
            '.cs': 'csharp',
            '.go': 'go',
            '.rs': 'rust',
            '.php': 'php',
            '.rb': 'ruby'
        }
        return language_map.get(file_extension.lower(), 'unknown')
    
    def _create_empty_analysis(self) -> Dict[str, Any]:
        """Create empty analysis result"""
        return {
            'copilot_confidence': 0.0,
            'confidence_score': 0.0,
            'estimated_lines': 0,
            'risk_level': 'MINIMAL',
            'language': 'unknown',
            'conservative_analysis': {
                'explicit_score': 0.0,
                'semantic_score': 0.0,
                'naming_score': 0.0,
                'structure_score': 0.0,
                'evasion_score': 0.0,
                'raw_confidence': 0.0,
                'calibration_applied': 0.0
            },
            'evasion_resistance': {
                'evasion_detected': False,
                'evasion_indicators': [],
                'maintains_detection': False
            },
            'explanation': ['Empty or invalid file content']
        }